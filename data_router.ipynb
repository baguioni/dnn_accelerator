{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bb014e4e-7a78-4be8-8930-ea6ade1aefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "N = 1   # Batch size\n",
    "K = 1   # Number of filters (output channels)\n",
    "C = 3   # Input channels\n",
    "W = 5   # Output width\n",
    "H = 5   # Output height\n",
    "R = 3   # Kernel/filter height\n",
    "S = 3   # Kernel/filter width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9fb262e8-9ef6-426b-8afb-0170d4f1cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_tensor(N, C, W, H):\n",
    "    return np.array(np.random.randint(0, 255, (N, C, W, H), dtype=np.uint8))\n",
    "\n",
    "def create_kernel_tensor(K, C, R, S):\n",
    "    # Filter dimensions: (K, C, R, S)\n",
    "    filter_tensor = np.zeros((K, C, R, S), dtype=np.uint8)\n",
    "    \n",
    "    # Fill the filter with identity matrices (1s along the diagonal)\n",
    "    for k in range(K):\n",
    "        for c in range(C):\n",
    "            for i in range(min(R, S)):  # Ensure it's square (R == S)\n",
    "                filter_tensor[k][c][i][i] = 1\n",
    "    return np.array((filter_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4e3c37ff-3af0-486c-9b3b-2c7cc8a94757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class to describe CNN dataflows or loop nests\n",
    "class data_flow(ABC):\n",
    "    def __init__(self, computation_unit, accumulator):\n",
    "        self.computation_unit = computation_unit\n",
    "        self.accumulator = accumulator\n",
    "\n",
    "    def compute_parameters(self, ifmap, kernel):\n",
    "        N, C, W, H = ifmap.shape\n",
    "        K, _, R, S = kernel.shape\n",
    "        X = W # Input width\n",
    "        Y = H # Input height\n",
    "        # Ignore padding and strides for now\n",
    "        W = W-S # Output width\n",
    "        H = H-R # Output height\n",
    "        return (N, K, C, W, H, R, S, X, Y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def execute(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "21dcb470-1444-4174-ad51-5dad59059f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline CNN representation\n",
    "class cnn_7d_loop_nest(data_flow):\n",
    "    def execute(self, ifmap, kernel):\n",
    "        cycles = 0\n",
    "        ifmap = np.array(ifmap)\n",
    "        kernel = np.array(kernel)\n",
    "        \n",
    "        N, K, C, W, H, R, S, X, Y = self.compute_parameters(ifmap, kernel)\n",
    "\n",
    "        # Output dimensions: (N, K, W, H)\n",
    "        output = np.zeros((N, K, W, H))\n",
    "        for n in range(N): # Loop over batch size\n",
    "            for k in range(K): # Loop over output channels (filters)\n",
    "                for c in range(C): # Loop over input channels\n",
    "                    for w in range(W): # Loop over output width\n",
    "                        for h in range(H): # Loop over output height\n",
    "                            for r in range(R): # Loop over kernel width\n",
    "                                for s in range(S): # Loop over kernel height\n",
    "                                    output[n][k][w][h] += ifmap[n][c][w+r][h+s] * kernel[k][c][r][s]\n",
    "                                    cycles += 1\n",
    "\n",
    "        return (output, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fe34b3ad-5d94-4a42-857d-29a4052184b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each individual PE represents a unit similar to a Fusion Unit. \n",
    "# In other words, it is composed of 16 Bitbricks and performs 8-bit by 8-bit multiplication\n",
    "class pe_array:\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    # fmap and weight can be shaped depending on algorithm for implementing cnn\n",
    "    def compute_psum(self, fmap, weight):\n",
    "        psums = []\n",
    "        for r in range(self.width):\n",
    "            for s in range(self.height):\n",
    "                psums.append(fmap[r][s] * weight[r][s])\n",
    "        return psums\n",
    "\n",
    "class accumulator_1d:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def accumulate(self, psums):\n",
    "        return sum(psums)\n",
    "\n",
    "# Sliding window approach\n",
    "# Assume PE array has dimensions equal to kernel\n",
    "class single_channel_sliding_window(data_flow):\n",
    "    def execute(self, ifmap, kernel):\n",
    "        cycles = 0\n",
    "        ifmap = np.array(ifmap)\n",
    "        kernel = np.array(kernel)\n",
    "        \n",
    "        N, K, C, W, H, R, S, X, Y = self.compute_parameters(ifmap, kernel)\n",
    "\n",
    "        # Output dimensions: (N, K, W, H)\n",
    "        output = np.zeros((N, K, W, H))\n",
    "\n",
    "        # Perform the convolution operation (iterating over the 7 nested loops)\n",
    "        for n in range(N): # Loop over batch size\n",
    "            for k in range(K): # Loop over output channels (filters)\n",
    "                for c in range(C): # Loop over input channels\n",
    "                    for w in range(W): # Loop over output width\n",
    "                        for h in range(H): # Loop over output height\n",
    "                            # Extract the sliding window of the feature map\n",
    "                            # sliding window has dimensions equal to kernel\n",
    "                            rows = ifmap[n][c][w:w+S]\n",
    "                            sliding_window = []\n",
    "                            for row in rows:\n",
    "                                sliding_window.append(list(row[h:h+R]))\n",
    "                            psums = self.computation_unit.compute_psum(sliding_window, kernel[k][c])\n",
    "                            accumulated_results = self.accumulator.accumulate(psums)\n",
    "                            output[n][k][w][h] += accumulated_results\n",
    "\n",
    "                            cycles += 1\n",
    "        return (output, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6dda7ad8-5df0-4002-8066-4e2e36d03e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class accumulator_2d:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def accumulate(self, psums):\n",
    "        final_sum = 0\n",
    "\n",
    "        for psum in psums:\n",
    "            final_sum += sum(psum)\n",
    "        return final_sum\n",
    "\n",
    "# Multi-channel sliding window approach\n",
    "# Assume PE Array is the same as number of input channels\n",
    "# Assume PE array has dimensions equal to kernel \n",
    "class multi_channel_sliding_window(data_flow):\n",
    "    def __init__(self, computation_unit, accumulator):\n",
    "        self.computation_unit = computation_unit\n",
    "        self.accumulator = accumulator\n",
    "        \n",
    "    def execute(self, ifmap, kernel):\n",
    "        cycles = 0\n",
    "        ifmap = np.array(ifmap)\n",
    "        kernel = np.array(kernel)\n",
    "        \n",
    "        N, K, C, W, H, R, S, X, Y = self.compute_parameters(ifmap, kernel)\n",
    "\n",
    "        # Output dimensions: (N, K, W, H)\n",
    "        output = np.zeros((N, K, W, H))\n",
    "\n",
    "        # Perform the convolution operation (iterating over the 7 nested loops)\n",
    "        for n in range(N): # Loop over batch size\n",
    "            for k in range(K): # Loop over output channels (filters)\n",
    "                    for w in range(W): # Loop over output width\n",
    "                        for h in range(H): # Loop over output height\n",
    "                            pe_input = []\n",
    "                            # Extract the sliding window of multiple channels the feature map\n",
    "                            for c in range(C): \n",
    "                                rows = ifmap[n][c][w:w+S]\n",
    "                                sliding_window = []\n",
    "                                for row in rows:\n",
    "                                    sliding_window.append(list(row[h:h+R]))\n",
    "                                pe_input.append(sliding_window)\n",
    "\n",
    "                            # Spatially unroll input channels or tensor elements\n",
    "                            # Frankly, this is not necessary since python wont execute this in parallel\n",
    "                            # but it should visualize the architecture\n",
    "                            psum_channel_0 = self.computation_unit.compute_psum(pe_input[0], kernel[k][0])\n",
    "                            psum_channel_1 = self.computation_unit.compute_psum(pe_input[1], kernel[k][1])\n",
    "                            psum_channel_2 = self.computation_unit.compute_psum(pe_input[2], kernel[k][2])\n",
    "                            accumulated_results = self.accumulator.accumulate([psum_channel_0, psum_channel_1, psum_channel_2])\n",
    "                            output[n][k][w][h] = accumulated_results\n",
    "\n",
    "                            cycles += 1\n",
    "        return (output, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2c832d4a-4784-46bf-b578-d765ad30f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tensor PE elements has same number of input channels\n",
    "class row_data_reuse(data_router):\n",
    "    def execute(self, ifmap, kernel):\n",
    "        cycles = 0\n",
    "        N_cpe = 1 # num of C-PE arrays\n",
    "        R = 1 # num of rows\n",
    "        T = 1 # num of C-PE in array\n",
    "        Pic = 1 # Parallelism of input channel\n",
    "        Poc = int(N_cpe/Pic/R)\n",
    "        ifmap = np.array(ifmap)\n",
    "        kernel = np.array(kernel)\n",
    "        \n",
    "        N, K, C, W, H, R, S, X, Y = self.compute_parameters(ifmap, kernel)\n",
    "\n",
    "        # Output dimensions: (N, K, W, H)\n",
    "        output = np.zeros((N, K, W, H), dtype=np.uint8)\n",
    "\n",
    "        # Perform the convolution operation (iterating over the 7 nested loops)\n",
    "        for n in range(N): # Loop over batch size\n",
    "            for x in range (0, X, R): # Loop over ifmap rows with stride R\n",
    "                for r in range(R): # Loop over each individual row\n",
    "                    for y in range(0, Y, T): # Loop over ifmap columns with stride T\n",
    "                        for oc in range(0, K, Poc): # loop over output channels with stride Poc\n",
    "                            for ic in range(0, C, Pic): # loop over input channels with stride Pic\n",
    "                                for i in range(R): # loop over kernel width\n",
    "                                    for j in range(S): # loop over kernel height\n",
    "                                        for ooc in range(oc):\n",
    "                                            for iic in range(ic):\n",
    "                                                output[n][ooc][x+R][y] += kernel[ooc][iic][i][j] * ifmap[icc][x+r+i][y+j]\n",
    "                                                cycles += 1\n",
    "        return (output, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bc4bbc35-9afa-4e38-b4fd-8ce26094cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Input Tensor--\n",
      "[[[[134 222 173 229 238]\n",
      "   [120 212 130 247 234]\n",
      "   [ 17 161 108  12 154]\n",
      "   [ 99 212 228 206  18]\n",
      "   [ 10 217   4 178  35]]\n",
      "\n",
      "  [[ 74 167 117 150 231]\n",
      "   [243 217 113  19 226]\n",
      "   [231  26  13  39 124]\n",
      "   [196 241 153   4  64]\n",
      "   [183  71 125 122  27]]\n",
      "\n",
      "  [[102 160  32  88 245]\n",
      "   [ 30  36 184  15 230]\n",
      "   [ 95 187 254  47 203]\n",
      "   [136 207  18  88  89]\n",
      "   [217 228  30 216 238]]]]\n",
      "\n",
      "--Kernel Tensor--\n",
      "[[[[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]]]\n",
      "3\n",
      "\n",
      "--Output Tensor (CNN loop nest)--\n",
      "[[[[1150. 1074.]\n",
      "   [1166. 1138.]]]] 108\n",
      "\n",
      "--Output Tensor (single-channel sliding window)--\n",
      "[[[[1150. 1074.]\n",
      "   [1166. 1138.]]]] 12\n",
      "\n",
      "--Output Tensor (multi-channel sliding window)--\n",
      "[[[[1150. 1074.]\n",
      "   [1166. 1138.]]]] 4\n",
      "\n",
      "--Output Tensor (Row data-reuse)--\n",
      "[[[[0 0]\n",
      "   [0 0]]]] 0\n"
     ]
    }
   ],
   "source": [
    "input_tensor = create_input_tensor(N, C, W, H)\n",
    "print(\"--Input Tensor--\")\n",
    "print(input_tensor)\n",
    "kernel_tensor = create_kernel_tensor(K, C, R, S)\n",
    "print(\"\\n--Kernel Tensor--\")\n",
    "print(kernel_tensor)\n",
    "\n",
    "# Default 7-D CNN Loop nest\n",
    "cnn = data_router(None, None)\n",
    "output, cycles = cnn.execute(input_tensor, kernel_tensor)\n",
    "print(\"\\n--Output Tensor (CNN loop nest)--\")\n",
    "print(output, cycles)\n",
    "\n",
    "# Single-channel of kernel fully maps to PE array\n",
    "accu = accumulator_1d()\n",
    "pe = pe_array(3,3)\n",
    "scsw = single_channel_sliding_window(pe, accu)\n",
    "output, cycles = scsw.execute(input_tensor, kernel_tensor)\n",
    "print(\"\\n--Output Tensor (single-channel sliding window)--\")\n",
    "print(output, cycles)\n",
    "\n",
    "# Multiple channels of kernel maps to PE array\n",
    "accu_unit = accumulator_2d()\n",
    "pe = pe_array(3,3)\n",
    "mcsw = multi_channel_sliding_window(pe, accu_unit)\n",
    "output, cycles = mcsw.execute(input_tensor, kernel_tensor)\n",
    "print(\"\\n--Output Tensor (multi-channel sliding window)--\")\n",
    "print(output, cycles)\n",
    "\n",
    "# Row data-reuse\n",
    "# WIP\n",
    "rdr = row_data_reuse(None, None)\n",
    "output, cycles = rdr.execute(input_tensor, kernel_tensor)\n",
    "print(\"\\n--Output Tensor (Row data-reuse)--\")\n",
    "print(output, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b73de-ee01-4ded-bbe7-899e5f0e7c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
