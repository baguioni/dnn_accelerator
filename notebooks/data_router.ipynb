{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb014e4e-7a78-4be8-8930-ea6ade1aefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "N = 1   # Batch size\n",
    "K = 1   # Number of filters (output channels)\n",
    "C = 3   # Input channels\n",
    "W = 5   # Output width\n",
    "H = 5  # Output height\n",
    "R = 3   # Kernel/filter height\n",
    "S = 3   # Kernel/filter width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fb262e8-9ef6-426b-8afb-0170d4f1cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_tensor(N, C, W, H):\n",
    "    return np.array(np.random.randint(0, 255, (N, C, W, H), dtype=np.uint8))\n",
    "\n",
    "def create_kernel_tensor(K, C, R, S):\n",
    "    # Filter dimensions: (K, C, R, S)\n",
    "    filter_tensor = np.zeros((K, C, R, S), dtype=np.uint8)\n",
    "    \n",
    "    # Fill the filter with identity matrices (1s along the diagonal)\n",
    "    for k in range(K):\n",
    "        for c in range(C):\n",
    "            for i in range(min(R, S)):  # Ensure it's square (R == S)\n",
    "                filter_tensor[k][c][i][i] = 1\n",
    "    return np.array((filter_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e3c37ff-3af0-486c-9b3b-2c7cc8a94757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class to describe CNN dataflows or loop nests\n",
    "class data_flow(ABC):\n",
    "    def __init__(self, computation_unit, accumulator):\n",
    "        self.computation_unit = computation_unit\n",
    "        self.accumulator = accumulator\n",
    "\n",
    "    def compute_parameters(self, ifmap, kernel):\n",
    "        N, C, W, H = ifmap.shape\n",
    "        K, _, R, S = kernel.shape\n",
    "        X = W # Input width\n",
    "        Y = H # Input height\n",
    "        # Ignore padding and strides for now\n",
    "        W = W-S+1 # Output width\n",
    "        H = H-R+1 # Output height\n",
    "        return (N, K, C, W, H, R, S, X, Y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def execute(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21dcb470-1444-4174-ad51-5dad59059f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline CNN representation\n",
    "class cnn_7d_loop_nest(data_flow):\n",
    "    def execute(self, ifmap, kernel):\n",
    "        cycles = 0\n",
    "        ifmap = np.array(ifmap)\n",
    "        kernel = np.array(kernel)\n",
    "        \n",
    "        N, K, C, W, H, R, S, X, Y = self.compute_parameters(ifmap, kernel)\n",
    "\n",
    "        # Output dimensions: (N, K, W, H)\n",
    "        output = np.zeros((N, K, W, H))\n",
    "        for n in range(N): # Loop over batch size\n",
    "            for k in range(K): # Loop over output channels (filters)\n",
    "                for c in range(C): # Loop over input channels\n",
    "                    for w in range(W): # Loop over output width\n",
    "                        for h in range(H): # Loop over output height\n",
    "                            for r in range(R): # Loop over kernel width\n",
    "                                for s in range(S): # Loop over kernel height\n",
    "                                    output[n][k][w][h] += ifmap[n][c][w+r][h+s] * kernel[k][c][r][s]\n",
    "                                    cycles += 1\n",
    "\n",
    "        return (output, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe34b3ad-5d94-4a42-857d-29a4052184b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each individual PE represents a unit similar to a Fusion Unit. \n",
    "# In other words, it is composed of 16 Bitbricks and performs 8-bit by 8-bit multiplication\n",
    "class pe_array:\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    # fmap and weight can be shaped depending on algorithm for implementing cnn\n",
    "    def compute_psum(self, fmap, weight):\n",
    "        psums = []\n",
    "        for r in range(self.width):\n",
    "            for s in range(self.height):\n",
    "                psums.append(fmap[r][s] * weight[r][s])\n",
    "        return psums\n",
    "\n",
    "class accumulator_1d:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def accumulate(self, psums):\n",
    "        return sum(psums)\n",
    "\n",
    "# Sliding window approach\n",
    "# Assume PE array has dimensions equal to kernel\n",
    "class single_channel_sliding_window(data_flow):\n",
    "    def execute(self, ifmap, kernel):\n",
    "        cycles = 0\n",
    "        ifmap = np.array(ifmap)\n",
    "        kernel = np.array(kernel)\n",
    "        \n",
    "        N, K, C, W, H, R, S, X, Y = self.compute_parameters(ifmap, kernel)\n",
    "\n",
    "        # Output dimensions: (N, K, W, H)\n",
    "        output = np.zeros((N, K, W, H))\n",
    "\n",
    "        # Perform the convolution operation (iterating over the 7 nested loops)\n",
    "        for n in range(N): # Loop over batch size\n",
    "            for k in range(K): # Loop over output channels (filters)\n",
    "                for c in range(C): # Loop over input channels\n",
    "                    for w in range(W): # Loop over output width\n",
    "                        for h in range(H): # Loop over output height\n",
    "                            # Extract the sliding window of the feature map\n",
    "                            # sliding window has dimensions equal to kernel\n",
    "                            rows = ifmap[n][c][w:w+S]\n",
    "                            sliding_window = []\n",
    "                            for row in rows:\n",
    "                                sliding_window.append(list(row[h:h+R]))\n",
    "\n",
    "                            print(sliding_window)\n",
    "                            psums = self.computation_unit.compute_psum(sliding_window, kernel[k][c])\n",
    "                            accumulated_results = self.accumulator.accumulate(psums)\n",
    "                            output[n][k][w][h] += accumulated_results\n",
    "\n",
    "                            cycles += 1\n",
    "        return (output, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dda7ad8-5df0-4002-8066-4e2e36d03e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class accumulator_2d:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def accumulate(self, psums):\n",
    "        final_sum = 0\n",
    "\n",
    "        for psum in psums:\n",
    "            final_sum += sum(psum)\n",
    "        return final_sum\n",
    "\n",
    "# Multi-channel sliding window approach\n",
    "# Assume PE Array is the same as number of input channels\n",
    "# Assume PE array has dimensions equal to kernel \n",
    "class multi_channel_sliding_window(data_flow):\n",
    "    def __init__(self, computation_unit, accumulator):\n",
    "        self.computation_unit = computation_unit\n",
    "        self.accumulator = accumulator\n",
    "        \n",
    "    def execute(self, ifmap, kernel):\n",
    "        cycles = 0\n",
    "        ifmap = np.array(ifmap)\n",
    "        kernel = np.array(kernel)\n",
    "        \n",
    "        N, K, C, W, H, R, S, X, Y = self.compute_parameters(ifmap, kernel)\n",
    "\n",
    "        # Output dimensions: (N, K, W, H)\n",
    "        output = np.zeros((N, K, W, H))\n",
    "\n",
    "        # Perform the convolution operation (iterating over the 7 nested loops)\n",
    "        for n in range(N): # Loop over batch size\n",
    "            for k in range(K): # Loop over output channels (filters)\n",
    "                    for w in range(W): # Loop over output width\n",
    "                        for h in range(H): # Loop over output height\n",
    "                            pe_input = []\n",
    "                            # Extract the sliding window of multiple channels the feature map\n",
    "                            for c in range(C): \n",
    "                                rows = ifmap[n][c][w:w+S]\n",
    "                                sliding_window = []\n",
    "                                for row in rows:\n",
    "                                    sliding_window.append(list(row[h:h+R]))\n",
    "                                pe_input.append(sliding_window)\n",
    "\n",
    "                            # Spatially unroll input channels or tensor elements\n",
    "                            # Frankly, this is not necessary since python wont execute this in parallel\n",
    "                            # but it should visualize the architecture\n",
    "                            psum_channel_0 = self.computation_unit.compute_psum(pe_input[0], kernel[k][0])\n",
    "                            psum_channel_1 = self.computation_unit.compute_psum(pe_input[1], kernel[k][1])\n",
    "                            psum_channel_2 = self.computation_unit.compute_psum(pe_input[2], kernel[k][2])\n",
    "                            accumulated_results = self.accumulator.accumulate([psum_channel_0, psum_channel_1, psum_channel_2])\n",
    "                            output[n][k][w][h] = accumulated_results\n",
    "\n",
    "                            cycles += 1\n",
    "        return (output, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c832d4a-4784-46bf-b578-d765ad30f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Assume tensor PE elements has same number of input channels\n",
    "class row_data_reuse(data_flow):\n",
    "    def execute(self, ifmap, kernel):\n",
    "        cycles = 0\n",
    "        N_cpe = 1 # num of C-PE arrays\n",
    "        R = 2 # num of rows\n",
    "        T = 2 # num of C-PE in array\n",
    "        Pic = 1 # Parallelism of input channel\n",
    "        Poc = math.ceil(N_cpe/Pic/R)\n",
    "        ifmap = np.array(ifmap)\n",
    "        kernel = np.array(kernel)\n",
    "        \n",
    "        N, K, C, W, H, R, S, X, Y = self.compute_parameters(ifmap, kernel)\n",
    "\n",
    "        # Output dimensions: (N, K, W, H)\n",
    "        output = np.zeros((N, K, W, H), dtype=np.uint8)\n",
    "\n",
    "        # Perform the convolution operation (iterating over the 7 nested loops)\n",
    "        for n in range(N): # Loop over batch size\n",
    "            for x in range (0, X, R): # Loop over ifmap rows with stride R\n",
    "                for r in range(R): # Loop over each individual row\n",
    "                    for y in range(0, Y, T): # Loop over column of input feature map with stride T\n",
    "                        for oc in range(0, K, Poc): # Loop over output channels with stride Poc\n",
    "                            for ic in range(0, C, Pic): # Loop over input channels with stride Pic\n",
    "                                for i in range(R):\n",
    "                                    if x+r >= X:\n",
    "                                        break\n",
    "                                    if y + i >= R:\n",
    "                                        break\n",
    "                                    print(ifmap[n][ic][x+r][y+i])\n",
    "                                print(\"--------\")\n",
    "                            print(\"-C-\")\n",
    "        return (output, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc4bbc35-9afa-4e38-b4fd-8ce26094cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Input Tensor--\n",
      "[[[[247 172 189  23 165]\n",
      "   [ 18 114 116 173 151]\n",
      "   [  6  17 152  58  32]\n",
      "   [ 30 143 157 247 132]\n",
      "   [233 181 167 203  18]]\n",
      "\n",
      "  [[ 44 214 252  24 211]\n",
      "   [215 120   5 173 152]\n",
      "   [226 147  42   3 132]\n",
      "   [220 238 237  74 166]\n",
      "   [202  65  33  95 248]]\n",
      "\n",
      "  [[ 45 131  94 203  31]\n",
      "   [  5 180 253 235 233]\n",
      "   [ 52 230 233 172   5]\n",
      "   [ 76 115   3   7  44]\n",
      "   [ 98 229  25 223  57]]]]\n",
      "\n",
      "--Kernel Tensor--\n",
      "[[[[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]\n",
      "   [0 0 1]]]]\n",
      "[[247, 172, 189], [18, 114, 116], [6, 17, 152]]\n",
      "[[172, 189, 23], [114, 116, 173], [17, 152, 58]]\n",
      "[[189, 23, 165], [116, 173, 151], [152, 58, 32]]\n",
      "[[18, 114, 116], [6, 17, 152], [30, 143, 157]]\n",
      "[[114, 116, 173], [17, 152, 58], [143, 157, 247]]\n",
      "[[116, 173, 151], [152, 58, 32], [157, 247, 132]]\n",
      "[[6, 17, 152], [30, 143, 157], [233, 181, 167]]\n",
      "[[17, 152, 58], [143, 157, 247], [181, 167, 203]]\n",
      "[[152, 58, 32], [157, 247, 132], [167, 203, 18]]\n",
      "[[44, 214, 252], [215, 120, 5], [226, 147, 42]]\n",
      "[[214, 252, 24], [120, 5, 173], [147, 42, 3]]\n",
      "[[252, 24, 211], [5, 173, 152], [42, 3, 132]]\n",
      "[[215, 120, 5], [226, 147, 42], [220, 238, 237]]\n",
      "[[120, 5, 173], [147, 42, 3], [238, 237, 74]]\n",
      "[[5, 173, 152], [42, 3, 132], [237, 74, 166]]\n",
      "[[226, 147, 42], [220, 238, 237], [202, 65, 33]]\n",
      "[[147, 42, 3], [238, 237, 74], [65, 33, 95]]\n",
      "[[42, 3, 132], [237, 74, 166], [33, 95, 248]]\n",
      "[[45, 131, 94], [5, 180, 253], [52, 230, 233]]\n",
      "[[131, 94, 203], [180, 253, 235], [230, 233, 172]]\n",
      "[[94, 203, 31], [253, 235, 233], [233, 172, 5]]\n",
      "[[5, 180, 253], [52, 230, 233], [76, 115, 3]]\n",
      "[[180, 253, 235], [230, 233, 172], [115, 3, 7]]\n",
      "[[253, 235, 233], [233, 172, 5], [3, 7, 44]]\n",
      "[[52, 230, 233], [76, 115, 3], [98, 229, 25]]\n",
      "[[230, 233, 172], [115, 3, 7], [229, 25, 223]]\n",
      "[[233, 172, 5], [3, 7, 44], [25, 223, 57]]\n",
      "\n",
      "--Output Tensor (single-channel sliding window)--\n"
     ]
    }
   ],
   "source": [
    "input_tensor = create_input_tensor(N, C, W, H)\n",
    "print(\"--Input Tensor--\")\n",
    "print(input_tensor)\n",
    "kernel_tensor = create_kernel_tensor(K, C, R, S)\n",
    "print(\"\\n--Kernel Tensor--\")\n",
    "print(kernel_tensor)\n",
    "\n",
    "\n",
    "# Single-channel of kernel fully maps to PE array\n",
    "accu = accumulator_1d()\n",
    "pe = pe_array(3,3)\n",
    "scsw = single_channel_sliding_window(pe, accu)\n",
    "output, cycles = scsw.execute(input_tensor, kernel_tensor)\n",
    "print(\"\\n--Output Tensor (single-channel sliding window)--\")\n",
    "#print(output, cycles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f7c53-e16b-499b-a49a-8b9e3f379f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
